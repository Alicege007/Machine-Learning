{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90cf94c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import *\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6d916f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark= SparkSession\\\n",
    "       .builder\\\n",
    "       .appName(\"concre-reall\")\\\n",
    "       .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "87df8426",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- user_id: integer (nullable = true)\n",
      " |-- anime_id: integer (nullable = true)\n",
      " |-- rating: integer (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rating_df=spark.read.csv('E:/Recomendation_sys_project/archive/rating.csv',header=True, inferSchema=True)\n",
    "rating_df.printSchema()\n",
    "rating_df=rating_df.where('rating>7')#评分大于7分的用户行为才表示推荐该电影"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dbed0de",
   "metadata": {},
   "source": [
    "# 1. Deep walk 构建动漫序列"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bc7a97",
   "metadata": {},
   "source": [
    "### 1.1 每个用户的anime观看序列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2620ba9f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "watch_seq_df=rating_df.groupby('user_id').agg(collect_list(col('anime_id').cast('string')).alias(\"anime_ids\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c672b0eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+--------------------+\n",
      "|user_id|           anime_ids|\n",
      "+-------+--------------------+\n",
      "|     31|[2581, 3784, 3785...|\n",
      "|     34|[20, 30, 32, 147,...|\n",
      "|     53|[101, 849, 1195, ...|\n",
      "|     65|[687, 853, 1221, ...|\n",
      "|     78|       [4224, 18153]|\n",
      "|     85|[223, 356, 481, 5...|\n",
      "|    108|[57, 61, 132, 147...|\n",
      "|    137|         [121, 5114]|\n",
      "|    148|[20, 81, 170, 263...|\n",
      "|    155|[164, 199, 226, 3...|\n",
      "+-------+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "watch_seq_df.show(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3e0c25",
   "metadata": {},
   "source": [
    "### 1.2 构建邻接矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a74191b3",
   "metadata": {},
   "source": [
    "这里数据是评分7分以上的电影，所以这里有一个假设，所有用户的评分行为表示用户喜欢和推荐该电影。\n",
    "构建邻接矩阵就是构建graph embedding， 每一个nodes之间出现连接线表示同时出现在某一个用户的评分列表里，如果两部电影之间被多个用户评价（喜爱），那这显示了两部电影之间有某种关系（或者相似度），所以可以形成序列。 根据这个序列放到word2vec的算法里计训练出的每一个动漫的embedding, 是使用用户行为反应两个动漫之间的相似度\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a5f4e8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_seq=watch_seq_df.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4e5bf909",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(user_id=31, anime_ids=['2581', '3784', '3785', '5680', '6347', '6634', '7791', '8516', '8769', '8841', '9471', '9617', '9760', '9919', '9938', '10087', '10408', '10793', '10897', '11499', '11737', '11741', '11757', '11843', '12291', '13055', '13759', '14467', '14741', '14811', '14813', '15225', '15315', '15687', '15699', '15809', '15879', '16005', '16417', '16524'])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "watch_seq[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "add99af2",
   "metadata": {},
   "outputs": [],
   "source": [
    "watch_seq1=[ w['anime_ids'] for w in watch_seq ]#形成的是一个二维的list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4218598f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>, {})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "matrix=defaultdict(lambda:defaultdict(int))\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fe2ca0b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100\n",
    "for i in range(n):\n",
    "    seq=watch_seq1[i]\n",
    "    for j in range(len(seq)):\n",
    "        for k in range(j+1,len(seq)):\n",
    "            a=seq[j]\n",
    "            b=seq[k]\n",
    "            if a==b:\n",
    "                continue\n",
    "            matrix[a][b]+=1\n",
    "            matrix[b][a]+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "561ed6cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aab25b89",
   "metadata": {},
   "source": [
    "### 1.3 概率转移矩阵"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f416a9e6",
   "metadata": {},
   "source": [
    " 这里数据是评分7分以上的电影，所以这里有一个假设，所以用户的评分行为表示用户喜欢和推荐该电影"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bc7a74e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_probs=defaultdict(lambda: defaultdict(list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e3dcb66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(<function __main__.<lambda>()>, {})"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "10a4a559",
   "metadata": {},
   "outputs": [],
   "source": [
    "trans_probs=defaultdict(lambda: defaultdict(list))\n",
    "def get_transfer_probs(vs):\n",
    "    neighbours=list(vs.keys())\n",
    "    total_weight=__builtin__.sum(vs.values())\n",
    "    probs=[weight/total_weight for weight in vs.values()]\n",
    "    return neighbours,probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a2f82439",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keys,indict in matrix.items():\n",
    "    neigh,probs=get_transfer_probs(indict)\n",
    "    trans_probs[keys]['neighbours']=neigh\n",
    "    trans_probs[keys][\"probs\"]=probs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fef3d024",
   "metadata": {},
   "source": [
    "### 1.4 随机选取入口node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b90e5b9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "entrence_items=list(trans_probs.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e14497c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_sum={i:__builtin__.sum(matrix[i].values()) for i in entrence_items}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "431108b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_sum=__builtin__.sum(nodes_sum.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9892c263",
   "metadata": {},
   "outputs": [],
   "source": [
    "entren_probs=[v/total_sum for k,v in nodes_sum.items()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d570c8",
   "metadata": {},
   "source": [
    "### 1.5 Deep walk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b7b67338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37c5bb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rng= np.random.default_rng()\n",
    "def one_walk(length,entrence_items,entrence_probs,transfer_probs):\n",
    "    path=[]\n",
    "    start_point=rng.choice(entrence_items,1,p=entrence_probs)[0]\n",
    "    path.append(str(start_point))\n",
    "    current_point=start_point\n",
    "    for _ in range(length):\n",
    "        next_point=rng.choice(transfer_probs[current_point]['neighbours'], 1, p=transfer_probs[current_point]['probs'])[0]\n",
    "        path.append(str(next_point))\n",
    "        current_point=next_point\n",
    "    return path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4ab0c10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "n=100#在实际的工作中，这个值可以更大，采样500是不够用的\n",
    "deepwalk_sample=[one_walk(19,entrence_items,entren_probs,trans_probs) for _ in range(n)]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06fcf65c",
   "metadata": {},
   "source": [
    "# 2. 训练每个动漫的Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff3adc91",
   "metadata": {},
   "source": [
    "### item2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420728ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "72381a0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|           anime_ids|\n",
      "+--------------------+\n",
      "|[9367, 558, 31043...|\n",
      "|[2923, 2034, 2089...|\n",
      "|[20031, 14813, 47...|\n",
      "|[9041, 8675, 2251...|\n",
      "|[6880, 19769, 72,...|\n",
      "|[23847, 28677, 28...|\n",
      "|[15809, 15613, 11...|\n",
      "|[4715, 22359, 221...|\n",
      "|[17895, 23673, 14...|\n",
      "|[513, 31098, 8740...|\n",
      "+--------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 要用spark的word2vec，所以要将原始的list转化成spark的df\n",
    "deepwalk_df=spark.createDataFrame([[row] for row in deepwalk_sample],['anime_ids'])\n",
    "deepwalk_df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f98e042d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0328b868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Word2Vec_31a6b85fdce1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "item2vec=Word2Vec(vectorSize=5,maxIter=2,windowSize=15)\n",
    "item2vec.setInputCol('anime_ids')\n",
    "item2vec.setOutputCol('anime_ids_vec')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c56250df",
   "metadata": {},
   "outputs": [],
   "source": [
    "model=item2vec.fit(deepwalk_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b163a7d",
   "metadata": {},
   "source": [
    "# 3. LSH查找最近邻动漫的Emdedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1cf124a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
